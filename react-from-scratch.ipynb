{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Annotated,\n",
    "    Sequence,\n",
    "    TypedDict,\n",
    ")\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import ToolMessage,SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import json\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=3)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, output_format='list')\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "model = ChatOllama(model=\"qwen2.5:32b\")\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''You are a Lab Assistant designed to assist with scientific experiments. Your task is to provide:\n",
    "\n",
    "Experiment Materials: A list of required materials and equipment.\n",
    "Experiment Steps: A detailed step-by-step guide for conducting the experiment.\n",
    "Safety Procedures: Essential precautions to ensure a safe experiment.\n",
    "Before generating the final response, you will:\n",
    "\n",
    "Search the query using DuckDuckGo to gather up-to-date and relevant information.\n",
    "Analyze the results to determine if the information is complete.\n",
    "Enhance the response by integrating the best available knowledge before providing the final answer.which is not a summary but well explained'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import base64\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class Crawl4AiTester:\n",
    "    def __init__(self, base_url: str = \"http://192.168.23.138:11235\", api_token: str = None):\n",
    "        self.base_url = base_url\n",
    "        self.api_token = (\n",
    "            api_token or os.getenv(\"CRAWL4AI_API_TOKEN\") or \"test_api_code\"\n",
    "        )  # Check environment variable as fallback\n",
    "        self.headers = (\n",
    "            {\"Authorization\": f\"Bearer {self.api_token}\"} if self.api_token else {}\n",
    "        )\n",
    "\n",
    "    def submit_and_wait(\n",
    "        self, request_data: Dict[str, Any], timeout: int = 300\n",
    "    ) -> Dict[str, Any]:\n",
    "        # Submit crawl job\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/crawl\", json=request_data, headers=self.headers\n",
    "        )\n",
    "        if response.status_code == 403:\n",
    "            raise Exception(\"API token is invalid or missing\")\n",
    "        task_id = response.json()[\"task_id\"]\n",
    "        print(f\"Task ID: {task_id}\")\n",
    "\n",
    "        # Poll for result\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(\n",
    "                    f\"Task {task_id} did not complete within {timeout} seconds\"\n",
    "                )\n",
    "\n",
    "            result = requests.get(\n",
    "                f\"{self.base_url}/task/{task_id}\", headers=self.headers\n",
    "            )\n",
    "            status = result.json()\n",
    "\n",
    "            if status[\"status\"] == \"failed\":\n",
    "                print(\"Task failed:\", status.get(\"error\"))\n",
    "                raise Exception(f\"Task failed: {status.get('error')}\")\n",
    "\n",
    "            if status[\"status\"] == \"completed\":\n",
    "                return status\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "    def submit_sync(self, request_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/crawl_sync\",\n",
    "            json=request_data,\n",
    "            headers=self.headers,\n",
    "            timeout=60,\n",
    "        )\n",
    "        if response.status_code == 408:\n",
    "            raise TimeoutError(\"Task did not complete within server timeout\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def crawl_direct(self, request_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Directly crawl without using task queue\"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/crawl_direct\", json=request_data, headers=self.headers\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "def test_docker_deployment(version=\"basic\"):\n",
    "    tester = Crawl4AiTester(\n",
    "        base_url=\"http://192.168.23.138:11235\",\n",
    "        # base_url=\"https://api.crawl4ai.com\" # just for example\n",
    "        # api_token=\"test\" # just for example\n",
    "    )\n",
    "    print(f\"Testing Crawl4AI Docker {version} version\")\n",
    "\n",
    "    # Health check with timeout and retry\n",
    "    max_retries = 5\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            health = requests.get(f\"{tester.base_url}/health\", timeout=10)\n",
    "            print(\"Health check:\", health.json())\n",
    "            break\n",
    "        except requests.exceptions.RequestException:\n",
    "            if i == max_retries - 1:\n",
    "                print(f\"Failed to connect after {max_retries} attempts\")\n",
    "                sys.exit(1)\n",
    "            print(f\"Waiting for service to start (attempt {i+1}/{max_retries})...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "    # Test cases based on version\n",
    "    # test_basic_crawl_direct(tester)\n",
    "    # test_basic_crawl(tester)\n",
    "    # test_basic_crawl(tester)\n",
    "    # test_basic_crawl_sync(tester)\n",
    "\n",
    "    # if version in [\"full\", \"transformer\"]:\n",
    "    #     test_cosine_extraction(tester)\n",
    "\n",
    "    # test_js_execution(tester)\n",
    "    # test_css_selector(tester)\n",
    "    # test_structured_extraction(tester)\n",
    "    # test_llm_extraction(tester)\n",
    "    test_llm_with_ollama(tester)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_llm_with_ollama(tester: Crawl4AiTester,url:str,schema:Union[dict,None]=None):\n",
    "    # print(\"\\n=== Testing LLM with Ollama ===\")\n",
    "    if schema is None:\n",
    "        schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"article_title\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The main title of the news article\",\n",
    "                },\n",
    "                \"summary\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"A brief summary of the article content\",\n",
    "                },\n",
    "                \"main_topics\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"Main topics or themes discussed in the article\",\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "    request = {\n",
    "        \"urls\": url,\n",
    "        \"priority\": 8,\n",
    "        \"extraction_config\": {\n",
    "            \"type\": \"llm\",\n",
    "            \"params\": {\n",
    "                \"provider\": \"qwen2.5:32b\",\n",
    "                \"base_url\":\"http://192.168.23.138:11439\",\n",
    "                \"schema\": schema,\n",
    "                \"extraction_type\": \"schema\",\n",
    "                \"instruction\": \"Extract the main article information including title, summary and if the article is about an experiment then extract materials, steps and safety procedures.\",\n",
    "            },\n",
    "        },\n",
    "        \"extra\": {\"word_count_threshold\": 1},\n",
    "        \"crawler_params\": {\"verbose\": True},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        result = tester.submit_and_wait(request)\n",
    "        extracted = json.loads(result[\"result\"][\"extracted_content\"])\n",
    "        return extracted\n",
    "        assert result[\"result\"][\"success\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama extraction test failed: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Crawl4AI Docker basic version\n",
      "Health check: {'status': 'healthy', 'available_slots': 7, 'memory_usage': 21.3, 'cpu_usage': 2.4}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "test_llm_with_ollama() missing 1 required positional argument: 'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_docker_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m, in \u001b[0;36mtest_docker_deployment\u001b[1;34m(version)\u001b[0m\n\u001b[0;32m     97\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Test cases based on version\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# test_basic_crawl_direct(tester)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# test_basic_crawl(tester)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# test_structured_extraction(tester)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# test_llm_extraction(tester)\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[43mtest_llm_with_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtester\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: test_llm_with_ollama() missing 1 required positional argument: 'url'"
     ]
    }
   ],
   "source": [
    "test_docker_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crawlerSchema(BaseModel):\n",
    "    title: str = Field(..., description=\"The title of the article\")\n",
    "    article: str = Field(..., description=\"rephrase the article so that it covers every part of the topic in a concise manner in about 500 words\")\n",
    "    # main_topics: str = Field(..., description=\"Main topics or themes discussed in the article\")\n",
    "    materials: str = Field( description=\"extract all the materials used in the experiment\")\n",
    "    steps: str = Field( description=\"exctract Step by step guide for conducting the experiment\")\n",
    "    safety_procedures: str = Field( description=\"Safety precautions for the experiment\")\n",
    "\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "def tool_node(state: AgentState):\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        if tool_call[\"name\"] == 'duckduckgo_results_json':\n",
    "            tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            toSearch = [search['link'] for search in tool_result]\n",
    "            print(toSearch)\n",
    "            crawler_result = None\n",
    "            pages_result = []\n",
    "            for url in toSearch:\n",
    "                # print(crawlerSchema.model_json_schema()['properties'])\n",
    "                \n",
    "                crawler_result = test_llm_with_ollama(tester=Crawl4AiTester(), url=url, schema=crawlerSchema.model_json_schema()['properties'])\n",
    "                # if crawler_result.get('success', False):  # Assuming the result has a 'success' flag\n",
    "                    # print(crawler_result)\n",
    "                # print(crawler_result)\n",
    "                pages_result.append(crawler_result)\n",
    "\n",
    "            crawler_result = json.dumps({\"search_results\": pages_result})\n",
    "            \n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=crawler_result,\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "    return {\"messages\": outputs}\n",
    "def call_model(\n",
    "    state: AgentState,\n",
    "    config: RunnableConfig,\n",
    "):\n",
    "    # this is similar to customizing the create_react_agent with 'prompt' parameter, but is more flexible\n",
    "    system_prompt = SystemMessage(\n",
    "        system_message\n",
    "    )\n",
    "    response = model.invoke([system_prompt] + state[\"messages\"], config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the conditional edge that determines whether to continue or not\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"tools\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Now we can compile and visualize our graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what should be the required materials and experiment procedure of the following lab Experiment (To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.)?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  duckduckgo_results_json (920e4d4c-5e60-4280-a538-bcfd4d862689)\n",
      " Call ID: 920e4d4c-5e60-4280-a538-bcfd4d862689\n",
      "  Args:\n",
      "    query: materials and steps to measure input and output impedance of Op-Amp\n",
      "['https://electronicmanufacturingservice.org/input-impedance-of-op-amp-what-it-is-and-how-to-calculate-it/', 'https://flexpcb.org/input-impedance-of-op-amp-what-it-is-and-how-to-calculate-it/', 'https://www.linkedin.com/pulse/input-impedance-op-amp-what-how-calculate-uraee', 'https://forum.allaboutcircuits.com/threads/output-resistance-measurment.204107/']\n",
      "Task ID: 636969eb-30c8-4439-a32a-926656b09d8a\n",
      "Task ID: 9ad27e87-03c2-4be3-af9c-ef92693a00c9\n",
      "Task ID: 72d75a16-d1d8-4885-a4e6-8f6a2ea604e7\n",
      "Task ID: ca2af442-b81e-43e0-9b57-e60e22c78fb9\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_results_json\n",
      "\n",
      "{\"search_results\": [[{\"title\": \"Input Impedance of Op-Amp: What It Is and How to Calculate It\", \"article\": \"The article likely discusses the concept of input impedance in operational amplifiers (op-amps), explaining its significance, how it affects circuit performance, and methods for calculating it. Input impedance is crucial as it determines how much load an op-amp can drive without affecting signal integrity. The calculation typically involves understanding the internal structure of the op-amp and applying relevant formulas.\", \"materials\": null, \"steps\": null, \"safety_procedures\": null, \"error\": false}], [{\"title\": \"Input Impedance of an Op-Amp Circuit\", \"article\": \"The article discusses the input impedance of an operational amplifier (op-amp) circuit, focusing on how it is influenced by the feedback network. The input impedance is crucial for determining how much signal voltage is lost when connected to a source with finite output impedance. It also affects the loading effect on preceding stages in a multi-stage amplifier system. The article explains that while op-amps have high input impedances due to their FET inputs, this can be significantly reduced by negative feedback. Negative feedback involves feeding back a portion of the output voltage to the inverting input, which lowers the effective impedance seen at the non-inverting input. This reduction is quantified by the formula Zin = (1 + A\\u03b2)Zi, where Zi is the op-amp's intrinsic input impedance, A is its open-loop gain, and \\u03b2 is the feedback factor. The article further elaborates on how different configurations like inverting and non-inverting amplifiers affect input impedance, with inverting amplifiers having a lower input impedance due to direct connection to the inverting terminal, while non-inverting amplifiers maintain high input impedance as they connect to the non-inverting terminal. Additionally, it touches upon practical considerations such as the impact of parasitic capacitance and frequency response on input impedance, emphasizing the importance of these factors in high-frequency applications.\", \"materials\": null, \"steps\": null, \"safety_procedures\": null, \"error\": false}], [{\"index\": 0, \"error\": true, \"tags\": [\"error\"], \"content\": \"litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen2.5:32b\\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\"}], [{\"index\": 0, \"error\": true, \"tags\": [\"error\"], \"content\": \"litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen2.5:32b\\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\"}, {\"index\": 0, \"error\": true, \"tags\": [\"error\"], \"content\": \"litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=qwen2.5:32b\\n Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\"}]]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results and additional knowledge, here is a detailed guide for measuring the input and output impedances of an operational amplifier (Op-Amp) in a given configuration:\n",
      "\n",
      "### Experiment Materials:\n",
      "1. **Operational Amplifier** - A general-purpose Op-Amp like the LM741.\n",
      "2. **Signal Generator**: To provide the input signal to the Op-Amp.\n",
      "3. **Oscilloscope**: To measure output voltage and observe waveforms.\n",
      "4. **Multimeter (Analog or Digital)**: For measuring voltages, currents, and resistances.\n",
      "5. **Resistors**: Various values for configuring feedback networks and loads.\n",
      "6. **Breadboard or Circuit Board**: For assembling the circuit.\n",
      "7. **Power Supply**: Dual power supply (+/-15V) to power the Op-Amp.\n",
      "8. **Connecting Wires**.\n",
      "\n",
      "### Experiment Steps:\n",
      "\n",
      "#### Step 1: Setup the Circuit\n",
      "- Connect the Op-Amp on a breadboard with appropriate connections for power supplies and ground.\n",
      "- Configure the circuit as an inverting or non-inverting amplifier based on your desired configuration. For this example, let's use an inverting amplifier configuration:\n",
      "    - Connect one end of resistor R1 (input resistance) to the signal generator output and the other end to the inverting terminal (-) of the Op-Amp.\n",
      "    - Connect a feedback resistor RF from the output of the Op-Amp back to its inverting input.\n",
      "\n",
      "#### Step 2: Measure Input Impedance\n",
      "- Apply a small AC voltage (e.g., 1V peak-to-peak) using the signal generator and measure the current flowing through R1 using an ammeter.\n",
      "- The input impedance \\( Z_{in} \\) can be calculated as:\n",
      "    \\[\n",
      "    Z_{in} = V_{in} / I_{in}\n",
      "    \\]\n",
      "    Where \\( V_{in} \\) is the voltage across R1 and \\( I_{in} \\) is the current through R1.\n",
      "\n",
      "#### Step 3: Measure Output Impedance\n",
      "- Apply a known input voltage to the Op-Amp.\n",
      "- Connect a load resistor RL to the output of the Op-Amp and measure the output voltage without any load (V_out_no_load).\n",
      "- Then, measure the output voltage with the load resistor connected (V_out_with_load).\n",
      "- The output impedance \\( Z_{out} \\) can be calculated as:\n",
      "    \\[\n",
      "    Z_{out} = R_L \\times \\left( \\frac{V_{out\\_no\\_load}}{V_{out\\_with\\_load} - V_{out\\_no\\_load}} \\right)\n",
      "    \\]\n",
      "\n",
      "### Safety Procedures:\n",
      "1. **Ensure Proper Grounding**: Always make sure that the circuit is properly grounded to avoid short circuits and ensure safety.\n",
      "2. **Use Appropriate Voltage Levels**: Be cautious with high voltage levels, especially when using dual power supplies. Use appropriate insulation and handling techniques.\n",
      "3. **Double-check Connections**: Before applying power, double-check all connections to ensure they are correct and secure.\n",
      "4. **Use Safety Equipment**: Wear protective eyewear if working with potentially hazardous equipment or components.\n",
      "\n",
      "By following these steps and ensuring safety precautions, you can effectively measure the input and output impedances of an operational amplifier in your desired configuration.\n"
     ]
    }
   ],
   "source": [
    "query = f\"what should be the required materials and experiment procedure of the following lab Experiment (To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.)?\"\n",
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "\n",
    "inputs = {\"messages\": [(\"user\", query)]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
