{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install langgraph langchain_ollama \n",
    "!pip install -qU duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.prebuilt import ToolNode\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "\n",
    "llm = ChatOllama(model=\"jacob-ebey/phi4-tools:latest\")\n",
    "# llm = ChatOllama(model=\"qwen2.5:32b\")\n",
    "# llm = ChatOllama(model=\"MFDoom/deepseek-r1-tool-calling:32b\")\n",
    "\n",
    "system = '''You are an AI assistant that follows a ReAct (Reasoning + Acting) framework to answer questions efficiently using search. You will think step by step, take appropriate actions, and provide observations before concluding with an answer. Follow the format strictly:\n",
    "\n",
    "Format:\n",
    "Question: The question asked.\n",
    "Thought: Reason logically about how to find the answer.\n",
    "Action: Choose an action. If search is needed, use Search[query]. If an answer is found, use Finish[answer].\n",
    "Observation: The result of the action.\n",
    "Repeat steps until the answer is found.\n",
    "Example 1:\n",
    "Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
    "Thought 1: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
    "Action 1: Search[Nicholas Ray]\n",
    "Observation 1: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
    "Thought 2: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
    "Action 2: Search[Elia Kazan]\n",
    "Observation 2: Elia Kazan was an American film and theatre director, producer, screenwriter, and actor.\n",
    "Thought 3: Professions of Elia Kazan are director, producer, screenwriter, and actor. So the profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
    "Action 3: Finish[director, screenwriter, actor]\n",
    "\n",
    "Example 2:\n",
    "Question: Which magazine was started first, Arthur’s Magazine or First for Women?\n",
    "Thought 1: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
    "Action 1: Search[Arthur’s Magazine]\n",
    "Observation 1: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
    "Thought 2: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
    "Action 2: Search[First for Women]\n",
    "Observation 2: First for Women is a women’s magazine published by Bauer Media Group in the USA. The magazine was started in 1989.\n",
    "Thought 3: First for Women was started in 1989. Since 1844 (Arthur’s Magazine) < 1989 (First for Women), Arthur’s Magazine was started first.\n",
    "Action 3: Finish[Arthur’s Magazine]\n",
    "\n",
    "Follow this process for all questions. Do not assume answers without searching. Always reason through each step before deciding on an action.'''\n",
    "\n",
    "tools = [search]\n",
    "toolLLMNode = llm.bind_tools(tools)\n",
    "toolNode = ToolNode(tools,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'jacob-ebey/phi4-tools:latest', 'created_at': '2025-02-07T04:19:44.82160498Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4603630054, 'load_duration': 3833287804, 'prompt_eval_count': 182, 'prompt_eval_duration': 216000000, 'eval_count': 41, 'eval_duration': 553000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-13a230cb-7bec-453b-b070-991c394a235b-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'current news in Delhi'}, 'id': 'bbd51ad7-18c5-4291-88d3-5296360ebed0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 182, 'output_tokens': 41, 'total_tokens': 223})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolLLMNode.invoke(\"what is the current news in delhi right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today\\'s Delhi News: Get all the Latest and Breaking Delhi News on NDTV. Live local Delhi news coverage and updates on Politics, Election, Weather, Crime and More Delhi News Live Updates: Chief Minister Atishi of the Aam Aadmi Party (AAP) Monday formally requested the Chief Election Commissioner (CEC) to conduct a fresh verification of voter deletions in the New Delhi Assembly constituency. This plea follows the Election Commission\\'s release of a revised ... Delhi Farmers Protest, Schools Bomb Threat Today Latest News Updates: \"On December 16, a tractor march will be organised outside Punjab, and on December 18, we have called for a \\'Rail Roko\\' in Punjab. We appeal to all Punjabis to participate in large numbers,\" Pandher said. Delhi News Live: From weather alerts to government announcements, the Delhi News Live blog provides real-time updates on everything that matters. Stay informed about the biggest stories affecting ... City Latest News Today Live: People take a dip in the Yamuna River near Kalindi Kunj in Delhi amid toxic foam on the first day of Chhath Puja 08:59 (IST) Nov 05 City Latest News Today Live: A ...'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = toolNode.invoke({\"messages\": [toolLLMNode.invoke(\"what is the current news in delhi right now\")]})\n",
    "t[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict,Annotated,Literal\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    intermediate_steps : Annotated[list,operator.add]\n",
    "    final_result: str\n",
    "    system_prompt: str\n",
    "    iteration:int\n",
    "    \n",
    "from pydantic import BaseModel,Field\n",
    "\n",
    "\n",
    "class Action(BaseModel):\n",
    "    # reason: str = Field(description=\"the input of the user and how do you reason the decision\")\n",
    "    reason: str=Field(description=\"which decision was chosen and why based on the action\") \n",
    "    decision: Literal[\"Finish\", \"ToolCall\"] = Field(description=\"the action to be chosen by evaluating the thought process. if the input is undecisive then call ToolCall otherwise Finish\")\n",
    "actionLLM = llm.with_structured_output(Action,method=\"json_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = actionLLM.invoke(\"i now have complete information now i can rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Action(reason=\"The user's statement is vague and does not provide enough context to determine if it contains sensitive information or requires a specific action. It could be interpreted as a personal reflection rather than something that needs moderation.\", decision='ToolCall')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def system_init(state:State):\n",
    "    # return llm.invoke(f\"based on the system prompt :{state['system']}\\n\\n plan the steps for the following question:{state['input']}\")\n",
    "def thinking_llm(state:State):\n",
    "    if state[\"iteration\"] !=0:\n",
    "        resp = llm.invoke(f\"Analyze the situation step by step based on the following context: {state['intermediate_steps']}. Clearly reason through each step and output the what do you need to do in order to perform the lab activity safely you have the access to web search if needed use that by asking that you need to search the web for the so and so.\\n \\n Thought {state['iteration']} :\" )\n",
    "        fs = state[\"intermediate_steps\"] + [f\"Thought {state['iteration']}\"+ resp.content]\n",
    "        state.update({\"intermediate_steps\": fs})\n",
    "        state.update({\"iteration\":state[\"iteration\"]+1})\n",
    "        \n",
    "        return state\n",
    "    else :\n",
    "        resp = llm.invoke(f\"given system_prompt [{state['system_prompt']}] and input {state['input']} output the thought. \\n\\n Thought {state['iteration']} :\")\n",
    "        fs = state[\"intermediate_steps\"] + [f\"Thought {state['iteration']}\"+ resp.content]\n",
    "        state.update({\"intermediate_steps\": fs})\n",
    "        state.update({\"iteration\":state[\"iteration\"]+1})\n",
    "        print(\"thinking...\")\n",
    "        return state\n",
    "\n",
    "def action_llm(state:State):\n",
    "    resp = actionLLM.invoke(f\"based on the following thought process should the model be calling a ToolCall or if the model has all information then it should call Finish. Based on the input {state['intermediate_steps'][-1]}\")\n",
    "    fs = state[\"intermediate_steps\"] + [f\"Action {state['iteration']}\"+ resp.reason]\n",
    "    state.update({\"intermediate_steps\": fs})\n",
    "    # state.update({\"iteration\":state[\"iteration\"]+1})\n",
    "    if resp.decision == \"Finish\":\n",
    "        print(\"choosing action to finish\")\n",
    "        return \"FinishingAgent\"\n",
    "    elif resp.decision == \"ToolCall\":\n",
    "        print(\"choosing action to use Tools\")\n",
    "        return \"ToolNode\"\n",
    "    \n",
    "def finishingNode(state:State):\n",
    "    resp = llm.invoke(f\"based on '{state['input']}' which is the user prompt and the LLMs Thought process [{state['intermediate_steps']}] generate a final response for the input prompt using the information from Thought Process.\")\n",
    "    # fs = state[\"intermediate_steps\"] + [resp.content]\n",
    "    state.update({\"final_result\": [resp.content]})\n",
    "    print(\"finished!\")\n",
    "    return state\n",
    "\n",
    "def toolingLLMNode(state:State):\n",
    "\n",
    "    resp = toolLLMNode.invoke(f'based on {str(state[\"intermediate_steps\"][-2:])} call the appropriate tool')\n",
    "    respToTool = toolNode.invoke({\"messages\":[resp]})\n",
    "    fs = state[\"intermediate_steps\"] + [f\"observation {state['iteration']}: \"+respToTool[\"messages\"][-1].content]\n",
    "    state.update({\"intermediate_steps\": fs})\n",
    "    print(\"running Tool\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e0b42f0b60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "build = StateGraph(State)\n",
    "build.add_node(\"ToolDecidingNode\",toolingLLMNode)\n",
    "# build.add_node(\"ToolNode\",toolNode)\n",
    "build.add_node(\"ThoughtNode\",thinking_llm)\n",
    "# build.add_node(\"actionNode\",action_llm)\n",
    "build.add_node(\"final_node\",finishingNode)\n",
    "\n",
    "build.add_edge(START,\"ThoughtNode\")\n",
    "# build.add_edge(\"ThoughtNode\",\"actionNode\")\n",
    "# build.add_edge(\"ToolDecidingNode\",\"ToolNode\")\n",
    "build.add_edge(\"ToolDecidingNode\", \"ThoughtNode\")\n",
    "build.add_conditional_edges(\"ThoughtNode\",action_llm,{\"ToolCall\":\"ToolDecidingNode\",\"FinishingAgent\":\"final_node\"})\n",
    "build.add_edge(\"final_node\",END)\n",
    "# build.set_entry_point(START)\n",
    "# build.set_finish_point(END)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = [\n",
    "    \"To verify the relationship between voltage (V), current (I), and resistance (R) in an electrical circuit, as expressed by Ohm's Law: V=IRV = IRV=IR\",\n",
    "    \"To apply Kirchhoff’s Voltage Law (KVL) and Kirchhoff’s Current Law (KCL) to analyze and validate simple electrical circuits.\",\n",
    "    \"To study the behavior of resistors in series and parallel configurations, including the equivalent resistance calculation.\",\n",
    "    \"To study the forward and reverse bias characteristics of a PN junction diode.\",\n",
    "    \"To analyze voltage regulation using a Zener diode.\",\n",
    "    \"To construct and analyze the performance of half-wave and full-wave rectifiers, both with and without filters.\",\n",
    "    \"To analyze and implement wave-shaping circuits using diodes for clipping and clamping applications.\",\n",
    "    \"To analyze the input and output characteristics of Bipolar Junction Transistors (BJTs) and Field-Effect Transistors (FETs).\",\n",
    "    \"To design a common emitter amplifier and analyze its frequency response.\",\n",
    "    \"To implement and analyze operational amplifier (Op-Amp) circuits: inverting, non-inverting, summing, and differentiator configurations.\",\n",
    "    \"To verify the operation of basic logic gates: AND, OR, NOT, NAND, NOR, XOR, and XNOR\",\n",
    "    \"To investigate the charging and discharging behavior of a capacitor in an RC circuit and understand the time constant.\",\n",
    "    \"To investigate the resonance behavior of an LC circuit and measure the resonant frequency.\",\n",
    "    \"To calibrate an oscilloscope for accurate measurements of voltage and time.\",\n",
    "    \"To determine the turns ratio of a transformer and verify the relationship between the primary and secondary voltages.\",\n",
    "    \"To construct and analyze a bridge rectifier circuit and compare its performance with a half-wave rectifier.\",\n",
    "    \"To study the frequency response of a low-pass filter and determine its cutoff frequency.\",\n",
    "    \"To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.\",\n",
    "    \"To generate and analyze Lissajous figures using an oscilloscope by applying two sinusoidal signals with different frequencies.\",\n",
    "    \"To study the magnetic field produced by a solenoid and verify the relationship between current and magnetic field strength.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "remaining_exp = copy.deepcopy(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "1\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "2\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "3\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "4\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "5\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "6\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "7\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "8\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "9\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "10\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "11\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "12\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "13\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "14\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "15\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "16\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "17\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "18\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "19\n",
      "thinking...\n",
      "choosing action to finish\n",
      "finished!\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "counting = 1\n",
    "for i in range(len(remaining_exp)):\n",
    "    graph = build.compile(checkpointer=memory)\n",
    "    config = {\"configurable\": {\"thread_id\": str(counting)}}\n",
    "    exp_name = remaining_exp.pop()\n",
    "    for event  in graph.stream({'input':f\"plan the following experiment {{{exp_name}}} and ensure that the experiments are with in the safety parameters also ensure that the output contains items required and experiments steps\",'intermediate_steps':[],'iteration':0,'system_prompt':system},config=config):\n",
    "        if \"final_node\" in event:\n",
    "            print(counting)\n",
    "            with open(\"experiments_generated_phi4.md\",'a',encoding=\"utf-8\") as F:\n",
    "                F.write(\"\\n---\\n\")\n",
    "                F.write(f\"# {counting} {exp_name}\\n\")\n",
    "                F.write(event['final_node']['final_result'][0])\n",
    "            with open(\"experiments_thoughts_phi4.md\",'a',encoding=\"utf-8\") as F:\n",
    "                F.write(\"\\n---\\n\")\n",
    "                F.write(f\"# {counting} {exp_name}\\n\")\n",
    "                F.write(event['final_node']['intermediate_steps'][0])\n",
    "            counting+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
