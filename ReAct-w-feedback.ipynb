{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Annotated,\n",
    "    Sequence,\n",
    "    TypedDict,\n",
    "    Union\n",
    ")\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import ToolMessage,SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import json\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    generated_exps: dict\n",
    "    exp_title:str\n",
    "    reward:Union[int,float]\n",
    "\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=2)\n",
    "search = DuckDuckGoSearchResults(api_wrapper=wrapper, output_format='list')\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "model = ChatOllama(model=\"jacob-ebey/phi4-tools:latest\")\n",
    "model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''You are a Lab Assistant designed to assist with scientific experiments. Your task is to provide:\n",
    "\n",
    "Experiment Materials: A list of required materials and equipment.\n",
    "Experiment Steps: A detailed step-by-step guide for conducting the experiment.\n",
    "Safety Procedures: Essential precautions to ensure a safe experiment.\n",
    "Before generating the final response, you will:\n",
    "\n",
    "Search the query using DuckDuckGo to gather up-to-date and relevant information.\n",
    "Analyze the results to determine if the information is complete.\n",
    "Enhance the response by integrating the best available knowledge before providing the final answer.which is not a summary but well explained'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class crawlerSchema(BaseModel):\n",
    "#     title: str = Field(..., description=\"The title of the article\")\n",
    "#     article: str = Field(..., description=\"rephrase the article so that it covers every part of the topic in a concise manner in about 500 words\")\n",
    "#     # main_topics: str = Field(..., description=\"Main topics or themes discussed in the article\")\n",
    "#     materials: str = Field( description=\"extract all the materials used in the experiment\")\n",
    "#     steps: str = Field( description=\"exctract Step by step guide for conducting the experiment\")\n",
    "#     safety_procedures: str = Field( description=\"Safety precautions for the experiment\")\n",
    "\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "def tool_node(state: AgentState):\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        if tool_call[\"name\"] == 'duckduckgo_results_json':\n",
    "            tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            toSearch = [search['link'] for search in tool_result]\n",
    "            # print(toSearch)\n",
    "            crawler_result = None\n",
    "            pages_result = []\n",
    "            return {\"messages\":str(tool_result)}\n",
    "            for url in toSearch:\n",
    "                # print(crawlerSchema.model_json_schema()['properties'])\n",
    "                \n",
    "                crawler_result = test_llm_with_ollama(tester=Crawl4AiTester(), url=url, schema=crawlerSchema.model_json_schema()['properties'])\n",
    "                # if crawler_result.get('success', False):  # Assuming the result has a 'success' flag\n",
    "                    # print(crawler_result)\n",
    "                # print(crawler_result)\n",
    "                pages_result.append(crawler_result)\n",
    "\n",
    "            crawler_result = json.dumps({\"search_results\": pages_result})\n",
    "            \n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=crawler_result,\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "    return {\"messages\": outputs}\n",
    "def call_model(\n",
    "    state: AgentState,\n",
    "    config: RunnableConfig,\n",
    "):\n",
    "    # this is similar to customizing the create_react_agent with 'prompt' parameter, but is more flexible\n",
    "    system_prompt = SystemMessage(\n",
    "        system_message\n",
    "    )\n",
    "    response = model.invoke([system_prompt] + state[\"messages\"], config)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Define the conditional edge that determines whether to continue or not\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"tools\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Now we can compile and visualize our graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = f\"what should be the required materials and experiment procedure of the following lab Experiment (To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.)?\"\n",
    "# def print_stream(stream):\n",
    "#     for s in stream:\n",
    "#         message = s[\"messages\"][-1]\n",
    "#         if isinstance(message, tuple):\n",
    "#             print(message)\n",
    "#         else:\n",
    "#             message.pretty_print()\n",
    "\n",
    "\n",
    "# inputs = {\"messages\": [(\"user\", query)]}\n",
    "# print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, MessagesState, StateGraph,END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import Union, Dict\n",
    "import json\n",
    "\n",
    "# formatter_llm = ChatOllama(model=\"jacob-ebey/phi4-tools:latest\",base_url=\"192.168.23.138:11439\")\n",
    "formatter_llm = model\n",
    "class score(BaseModel):\n",
    "    score1: float = Field(le=1.0,ge=0.0,description=\"probability of getting the score of 1\")\n",
    "    score2: float = Field(le=1.0,ge=0.0,description=\"probability of getting the score of 2\")\n",
    "    score3: float = Field(le=1.0,ge=0.0,description=\"probability of getting the score of 3\")\n",
    "    score4: float = Field(le=1.0,ge=0.0,description=\"probability of getting the score of 4\")\n",
    "    score5: float = Field(le=1.0,ge=0.0,description=\"probability of getting the score of 5\")\n",
    "\n",
    "class JsonnedOutput(BaseModel):\n",
    "    Accuracy: score = Field(...,description=\"ratings of the Accuracy in a probabilstic distribution manner\")\n",
    "    Completeness: score = Field(...,description=\"ratings of the Completeness in a probabilstic distribution manner\")\n",
    "    Clarity: score = Field(...,description=\"ratings of the Clarity in a probabilstic distribution manner\")\n",
    "    Safety:score = Field(...,description=\"ratings of the Safety in a probabilstic distribution manner\")\n",
    "\n",
    "def generate_evaluation_prompt(ground_truth: Dict, test_procedure: str) -> str:\n",
    "    return f\"\"\"\n",
    "        You are an expert evaluator assessing the accuracy, completeness, clarity, and safety of a scientific experiment procedure.\n",
    "\n",
    "        ### **Task**\n",
    "        Compare the **Test Procedure** against the **Ground Truth** and evaluate it across four key dimensions. Provide a **probability distribution over scores [1,2,3,4,5]** for each category.\n",
    "\n",
    "        ### **Evaluation Criteria**\n",
    "        1. **Accuracy**: Are the components and steps correct?\n",
    "        2. **Completeness**: Are all critical steps present?\n",
    "        3. **Clarity**: Is the procedure easy to follow?\n",
    "        4. **Safety**: Are safety precautions included?\n",
    "\n",
    "        ### **Response Format (Strict JSON)**\n",
    "        ```json\n",
    "        {{\n",
    "            \"Accuracy\": {{ \"score1\": p1, \"score2\": p2, \"score3\": p3, \"score4\": p4, \"score5\": p5 }},\n",
    "            \"Completeness\": {{ \"score1\": p1, \"score2\": p2, \"score3\": p3, \"score4\": p4, \"score5\": p5 }},\n",
    "            \"Clarity\": {{ \"score1\": p1, \"score2\": p2, \"score3\": p3, \"score4\": p4, \"score5\": p5 }},\n",
    "            \"Safety\": {{ \"score1\": p1, \"score2\": p2, \"score3\": p3, \"score4\": p4, \"score5\": p5 }}\n",
    "        }}\n",
    "        Each probability value must be between 0 and 1 and sum to 1.\n",
    "\n",
    "        ### **Ground Truth**\n",
    "        {json.dumps(ground_truth, indent=4)}\n",
    "\n",
    "        ### **Test Procedure**\n",
    "        {test_procedure}\n",
    "        \"\"\"\n",
    "\n",
    "formatter = model.with_structured_output(JsonnedOutput,method='json_mode')\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    output: Union[JsonnedOutput,None]\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "def generate_graph_evaluation(state:State):\n",
    "    # print(state[\"input\"])\n",
    "    response = model.invoke(state[\"input\"])\n",
    "    # print(\"----------------------------->\",response)\n",
    "    formatted_response = formatter.invoke(f\"based on the {response.content} only output probabilities of each criteria and Leave everything. OUTPUT in the following json manner {{'Accuracy': {{ 'score1': p1, 'score2': p2, 'score3': p3, 'score4': p4, 'score5': p5 }}, 'Completeness': {{ 'score1': p1, 'score2': p2, 'score3': p3, 'score4': p4, 'score5': p5 }}, 'Clarity': {{ 'score1': p1, 'score2': p2, 'score3': p3, 'score4': p4, 'score5': p5 }},'Safety': {{ 'score1': p1, 'score2': p2, 'score3': p3, 'score4': p4, 'score5': p5 }} }} but ensure that the json format is correct\")\n",
    "    # print(formatted_response)\n",
    "    return {\"output\":{\"Accuracy\": formatted_response.Accuracy, \"Completeness\": formatted_response.Completeness,\"Clarity\":formatted_response.Clarity,\"Safety\": formatted_response.Safety}}\n",
    "\n",
    "workflow.add_node(\"evaluator\",generate_graph_evaluation)\n",
    "workflow.add_edge(START,\"evaluator\")\n",
    "workflow.add_edge(\"evaluator\",END)\n",
    "eval_graph = workflow.compile()\n",
    "import os\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    try:\n",
    "        files = os.listdir(directory)\n",
    "        return files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The directory {directory} does not exist.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied to access the directory {directory}.\")\n",
    "from typing import Dict, Optional\n",
    "def evaluate_experiment(ground_truth: Dict, test_procedure: str):\n",
    "    prompt = generate_evaluation_prompt(ground_truth, test_procedure)\n",
    "\n",
    "\n",
    "    event = eval_graph.invoke({\"input\": prompt, \"output\": None })\n",
    "        # print(event)\n",
    "    # Debug: Print the raw response to see what the model is returning\n",
    "    try:\n",
    "        return event['output']\n",
    "    except KeyError:\n",
    "        return event\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from typing import Dict, Optional\n",
    "from typing import TypedDict,Literal\n",
    "import tqdm\n",
    "# logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s: %(message)s\")\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_json(filepath: str) -> Dict:\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # logger.error(f\"File not found: {filepath}\")\n",
    "        print(\"file not found\")\n",
    "        raise\n",
    "    except json.JSONDecodeError:\n",
    "        # logger.error(f\"Invalid JSON in file: {filepath}\")\n",
    "        print(\"file not found\")\n",
    "        raise\n",
    "def extract_json_from_response(response_text: str) -> Optional[Dict]:\n",
    "    try:\n",
    "        json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)  # Extracts only JSON part\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group())\n",
    "        else:\n",
    "            # logger.error(\"No valid JSON found in response.\")\n",
    "            print(\"file not found\")\n",
    "            return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        # logger.error(f\"JSON parsing error: {e}\")\n",
    "        print(\"file not found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "from typing import Union, Literal\n",
    "import json\n",
    "\n",
    "def load_json(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def run_evaluation(\n",
    "    ground_truth_path: str, \n",
    "    results_path: Union[str, dict],  \n",
    "    plots: dict, \n",
    "    mode: Literal[\"feedback\", \"judge\"] = \"judge\"\n",
    "):\n",
    "    # Load ground truth data\n",
    "    ground_truth_data = load_json(ground_truth_path)\n",
    "    ground_truth_dict = {exp[\"title\"]: exp for exp in ground_truth_data[\"experiments\"]}\n",
    "\n",
    "    # Load LLM generated results based on mode\n",
    "    if mode == \"judge\":\n",
    "        llm_generated_results = load_json(results_path)[\"experiments\"]\n",
    "    elif mode == \"feedback\":\n",
    "        llm_generated_results = results_path\n",
    "\n",
    "    # Initialize evaluation results\n",
    "    for chosen_exps in llm_generated_results:\n",
    "        for title, test_procedure in chosen_exps.items():\n",
    "            ground_truth = ground_truth_dict.get(title)\n",
    "\n",
    "            if ground_truth:\n",
    "                # Evaluate the experiment\n",
    "                result = evaluate_experiment(ground_truth, test_procedure)\n",
    "                # print(result)\n",
    "                # print(result)\n",
    "                # Aggregate scores into plots\n",
    "                for key, values in result.items():\n",
    "                    # print(values)\n",
    "                    score = (\n",
    "                        1 * float(values.score1) +\n",
    "                        2 * float(values.score2) +\n",
    "                        3 * float(values.score3) +\n",
    "                        4 * float(values.score4) +\n",
    "                        5 * float(values.score5)\n",
    "                    )\n",
    "                    plots[key].append(score)\n",
    "\n",
    "    # Handle output based on mode\n",
    "    if mode == \"judge\":\n",
    "        return plots\n",
    "    else:\n",
    "        # return 4.0\n",
    "        total_reward = sum(plots[key][-1] for key in plots.keys())\n",
    "        average_reward = total_reward / len(plots.keys())\n",
    "        return average_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_generator(state:AgentState):\n",
    "    response = graph.invoke({\"messages\":  state[\"messages\"][-1]})\n",
    "\n",
    "    return{\"generated_exps\":{state[\"exp_title\"]: response[\"messages\"][-1].content}}\n",
    "\n",
    "def run_evalutator(state:AgentState):\n",
    "    gt = \"non_code_files/experiments_2.json\"\n",
    "    plots = {'Accuracy':[],'Clarity':[],'Completeness':[],'Safety':[]}\n",
    "    response = run_evaluation(ground_truth_path=gt,results_path=[state[\"generated_exps\"]],mode=\"feedback\",plots=plots)\n",
    "    # print(response)\n",
    "    return {\"reward\":response}\n",
    "\n",
    "def continue_condition(state:AgentState):\n",
    "    if state[\"reward\"] < 4.2:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"finish\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_workflow = StateGraph(AgentState)\n",
    "feedback_workflow.add_node(\"generator\",run_generator)\n",
    "feedback_workflow.add_node(\"evaluatons\",run_evalutator)\n",
    "feedback_workflow.set_entry_point(\"generator\")\n",
    "feedback_workflow.add_conditional_edges(\"evaluatons\",continue_condition,{\"continue\":\"generator\",\"finish\":END})\n",
    "feedback_workflow.add_edge(\"generator\",\"evaluatons\")\n",
    "feedback_graph = feedback_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_name = \"To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.\"\n",
    "query = f\"what should be the required materials and experiment procedure of the following lab Experiment ({exps_name})?\"\n",
    "state= AgentState()\n",
    "inputs = {\"messages\": [(\"user\", query)],\"exp_title\":exps_name}\n",
    "# for event in feedback_graph.stream(inputs):\n",
    "#     # p\n",
    "#     print(event)\n",
    "event = feedback_graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.': \"To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration, you will need specific materials and follow a detailed procedure. Here's how you can set up your experiment:\\n\\n### Experiment Materials\\n\\n1. **Operational Amplifier**: Choose an appropriate Op-Amp model for your circuit.\\n2. **Power Supply**: Ensure it matches the voltage requirements of your Op-Amp (e.g., 3V-32V or ±1.5V to ±16V).\\n3. **Function Generator**: To provide input signals at various frequencies.\\n4. **Oscilloscope**: For measuring output voltages and analyzing waveforms.\\n5. **Multimeter**: For precise voltage measurements.\\n6. **Resistors and Capacitors**: Various values for testing different configurations.\\n7. **Breadboard or PCB**: For assembling the circuit.\\n8. **Connecting Wires**: To connect components.\\n\\n### Experiment Steps\\n\\n1. **Circuit Setup**:\\n   - Assemble the Op-Amp in the desired configuration on a breadboard or PCB.\\n   - Connect the power supply to the Op-Amp, ensuring correct polarity and voltage levels.\\n\\n2. **Input Impedance Measurement**:\\n   - Apply a known AC signal from the function generator to the input of the Op-Amp.\\n   - Measure the input current using an ammeter in series with the input or calculate it based on voltage drop across a known resistor.\\n   - Use Ohm's Law (\\\\(Z_{in} = V_{in}/I_{in}\\\\)) to calculate the input impedance at different frequencies.\\n\\n3. **Output Impedance Measurement**:\\n   - Connect a load resistor (R_L) to the output of the Op-Amp.\\n   - Measure the open-circuit voltage (\\\\(V_{oc}\\\\)) across the load without it connected and the loaded voltage (\\\\(V_{L}\\\\)) with it connected.\\n   - Calculate the output impedance using the formula: \\n     \\\\[\\n     Z_{out} = R_L \\\\times \\\\left(\\\\frac{V_{oc} - V_{L}}{V_{L}}\\\\right)\\n     \\\\]\\n\\n4. **Frequency Variation**:\\n   - Repeat the measurements at different frequencies to observe how input and output impedances vary with frequency.\\n\\n5. **Data Recording**:\\n   - Record all voltage, current, and impedance values systematically for analysis.\\n\\n### Safety Procedures\\n\\n- Ensure all connections are secure to prevent short circuits.\\n- Double-check power supply settings before powering the circuit.\\n- Use appropriate personal protective equipment (PPE) like safety glasses.\\n- Be cautious with high-voltage components to avoid electric shock.\\n\\nBy following these steps, you can effectively measure and analyze the input and output impedances of an Op-Amp in your chosen configuration.\"}\n"
     ]
    }
   ],
   "source": [
    "print(event[\"generated_exps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = [\n",
    "    \"To verify the relationship between voltage (V), current (I), and resistance (R) in an electrical circuit, as expressed by Ohm's Law: V=IRV = IRV=IR\",\n",
    "    \"To apply Kirchhoff’s Voltage Law (KVL) and Kirchhoff’s Current Law (KCL) to analyze and validate simple electrical circuits.\",\n",
    "    \"To study the behavior of resistors in series and parallel configurations, including the equivalent resistance calculation.\",\n",
    "    \"To study the forward and reverse bias characteristics of a PN junction diode.\",\n",
    "    \"To analyze voltage regulation using a Zener diode.\",\n",
    "    \"To construct and analyze the performance of half-wave and full-wave rectifiers, both with and without filters.\",\n",
    "    \"To analyze and implement wave-shaping circuits using diodes for clipping and clamping applications.\",\n",
    "    \"To analyze the input and output characteristics of Bipolar Junction Transistors (BJTs) and Field-Effect Transistors (FETs).\",\n",
    "    \"To design a common emitter amplifier and analyze its frequency response.\",\n",
    "    \"To implement and analyze operational amplifier (Op-Amp) circuits: inverting, non-inverting, summing, and differentiator configurations.\",\n",
    "    \"To verify the operation of basic logic gates: AND, OR, NOT, NAND, NOR, XOR, and XNOR\",\n",
    "    \"To investigate the charging and discharging behavior of a capacitor in an RC circuit and understand the time constant.\",\n",
    "    \"To investigate the resonance behavior of an LC circuit and measure the resonant frequency.\",\n",
    "    \"To calibrate an oscilloscope for accurate measurements of voltage and time.\",\n",
    "    \"To determine the turns ratio of a transformer and verify the relationship between the primary and secondary voltages.\",\n",
    "    \"To construct and analyze a bridge rectifier circuit and compare its performance with a half-wave rectifier.\",\n",
    "    \"To study the frequency response of a low-pass filter and determine its cutoff frequency.\",\n",
    "    \"To measure the input and output impedances of an operational amplifier (Op-Amp) in a given configuration.\",\n",
    "    \"To generate and analyze Lissajous figures using an oscilloscope by applying two sinusoidal signals with different frequencies.\",\n",
    "    \"To study the magnetic field produced by a solenoid and verify the relationship between current and magnetic field strength.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_title\u001b[39m\u001b[38;5;124m\"\u001b[39m:exps_name}\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# for event in feedback_graph.stream(inputs):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     # p\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     print(event)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mfeedback_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(exp)\n\u001b[0;32m     11\u001b[0m experiment_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_exps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32md:\\python\\agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2069\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32md:\\python\\agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1744\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1736\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[0;32m   1737\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1738\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1742\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[0;32m   1743\u001b[0m     )\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[1;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "experiment_dict = {\"experiments\":[]}\n",
    "for exp in experiment_name:\n",
    "    query = f\"what should be the required materials and experiment procedure of the following lab Experiment ({exp})?\"\n",
    "    state= AgentState()\n",
    "    inputs = {\"messages\": [(\"user\", query)],\"exp_title\":exps_name}\n",
    "    # for event in feedback_graph.stream(inputs):\n",
    "    #     # p\n",
    "    #     print(event)\n",
    "    event = feedback_graph.invoke(inputs)\n",
    "    print(exp)\n",
    "    experiment_dict[\"experiments\"].append(event[\"generated_exps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"phi4_exps_w_feedback/phi4_feedback_output_0.json\",\"w\") as F:\n",
    "    json.dump(experiment_dict,F,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exps.json\",\"w\") as F:\n",
    "    F.write(json.dumps(experiment_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
